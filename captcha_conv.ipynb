{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.Session(config=config)\n",
    "\n",
    "base_dir = 'D:\\src\\captchagen\\out'\n",
    "rerun_0 = 0\n",
    "rerun_1 = 1\n",
    "\n",
    "IMAGE_HEIGHT = 60\n",
    "IMAGE_WIDTH = 180\n",
    "MAX_NUM_LEN = 10000\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "def convert2gray(img):\n",
    "    if len(img.shape) > 2:\n",
    "        gray = np.mean(img, -1)\n",
    "        return gray\n",
    "    else:\n",
    "        return img\n",
    "    \n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "MAXLABEL = 40\n",
    "def num2vec(num):\n",
    "    if num < 0 or num > 9999 :\n",
    "        raise ValueError('number not in range 0-9999')\n",
    "    vector = np.zeros(MAXLABEL)\n",
    "    i = 0\n",
    "    while int(num) > 0:\n",
    "        idx = i * 10 + int(num) % 10\n",
    "        #print(idx)\n",
    "        num /= 10\n",
    "        i += 1\n",
    "        vector[idx] = 1 \n",
    "    return vector\n",
    "\n",
    "train_num = 10000\n",
    "\n",
    "train_set = np.ndarray(shape=(train_num, IMAGE_HEIGHT, IMAGE_WIDTH),dtype=np.float32)\n",
    "train_label = np.ndarray(shape=(train_num, MAXLABEL),dtype=np.float32)\n",
    "\n",
    "for i in range(train_num) :\n",
    "    fname = '{}.png'.format(i)\n",
    "    file = os.path.join(train_dir,fname)\n",
    "    img = image.load_img(file, target_size=(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "    arr = np.asarray(img,dtype=\"float32\")/255.0\n",
    "    arr = convert2gray(arr)\n",
    "    train_set[i] = arr    \n",
    "    train_label[i] = num2vec(i)\n",
    "\n",
    "val_num = 10000\n",
    "val_set = np.ndarray(shape=(val_num, IMAGE_HEIGHT, IMAGE_WIDTH),dtype=np.float32)\n",
    "val_label = np.ndarray(shape=(val_num, MAXLABEL),dtype=np.float32)\n",
    "\n",
    "for i in range(val_num) :\n",
    "    fname = '{}.png'.format(i)\n",
    "    file = os.path.join(validation_dir,fname)\n",
    "    img = image.load_img(file, target_size=(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "    arr = np.asarray(img,dtype=\"float32\")/255.0\n",
    "    arr = convert2gray(arr)\n",
    "    val_set[i] = arr    \n",
    "    val_label[i] = num2vec(i)\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "imgplot = plt.imshow(image.array_to_img(val_set[4].reshape(IMAGE_HEIGHT,IMAGE_WIDTH,1)))\n",
    "plt.figure(2)\n",
    "imgplot = plt.imshow(image.array_to_img(train_set[4].reshape(IMAGE_HEIGHT,IMAGE_WIDTH,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 40)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set.shape\n",
    "val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 60, 180, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = train_set.reshape((train_num,IMAGE_HEIGHT, IMAGE_WIDTH,1))\n",
    "val_set = val_set.reshape((val_num,IMAGE_HEIGHT, IMAGE_WIDTH,1))\n",
    "\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 58, 178, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 29, 89, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 27, 87, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 13, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 11, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 5, 20, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 3, 18, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 40)                2600      \n",
      "=================================================================\n",
      "Total params: 316,648\n",
      "Trainable params: 316,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense (64, activation = 'relu'))\n",
    "model.add(layers.Dense (40, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 8s 750us/step - loss: 11.4353 - acc: 0.2456 - val_loss: 11.0451 - val_acc: 0.2818\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28180, saving model to weights-improvement-01-0.28.hdf5\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 7s 744us/step - loss: 10.6146 - acc: 0.2948 - val_loss: 9.7388 - val_acc: 0.3798\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.28180 to 0.37980, saving model to weights-improvement-02-0.38.hdf5\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 9.9599 - acc: 0.3220 - val_loss: 9.2926 - val_acc: 0.3832\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.37980 to 0.38320, saving model to weights-improvement-03-0.38.hdf5\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 8s 752us/step - loss: 9.4255 - acc: 0.3366 - val_loss: 8.5401 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.38320 to 0.40930, saving model to weights-improvement-04-0.41.hdf5\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 8.9281 - acc: 0.3589 - val_loss: 8.1397 - val_acc: 0.4125\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.40930 to 0.41250, saving model to weights-improvement-05-0.41.hdf5\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 8.5110 - acc: 0.3778 - val_loss: 7.7321 - val_acc: 0.4378\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.41250 to 0.43780, saving model to weights-improvement-06-0.44.hdf5\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 8.2131 - acc: 0.3811 - val_loss: 7.6305 - val_acc: 0.4358\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.43780\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 7.9604 - acc: 0.3931 - val_loss: 7.2802 - val_acc: 0.4482\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.43780 to 0.44820, saving model to weights-improvement-08-0.45.hdf5\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 7.7710 - acc: 0.3986 - val_loss: 7.1392 - val_acc: 0.4489\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.44820 to 0.44890, saving model to weights-improvement-09-0.45.hdf5\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 8s 753us/step - loss: 7.6130 - acc: 0.4057 - val_loss: 6.9873 - val_acc: 0.4759\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.44890 to 0.47590, saving model to weights-improvement-10-0.48.hdf5\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 8s 759us/step - loss: 7.4796 - acc: 0.4194 - val_loss: 6.8970 - val_acc: 0.4279\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.47590\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 7.3603 - acc: 0.4180 - val_loss: 6.9030 - val_acc: 0.4737\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.47590\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 7s 748us/step - loss: 7.2505 - acc: 0.4261 - val_loss: 6.7594 - val_acc: 0.4793\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.47590 to 0.47930, saving model to weights-improvement-13-0.48.hdf5\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 7.1544 - acc: 0.4311 - val_loss: 6.6658 - val_acc: 0.5002\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.47930 to 0.50020, saving model to weights-improvement-14-0.50.hdf5\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 8s 763us/step - loss: 7.0804 - acc: 0.4252 - val_loss: 6.6029 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.50020\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 8s 762us/step - loss: 6.9925 - acc: 0.4355 - val_loss: 6.4513 - val_acc: 0.4898\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.50020\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 8s 759us/step - loss: 6.9350 - acc: 0.4328 - val_loss: 6.4645 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.50020\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 8s 762us/step - loss: 6.8701 - acc: 0.4325 - val_loss: 6.3389 - val_acc: 0.4507\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.50020\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 8s 750us/step - loss: 6.8218 - acc: 0.4306 - val_loss: 6.3001 - val_acc: 0.4872\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.50020\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 8s 752us/step - loss: 6.7585 - acc: 0.4313 - val_loss: 6.4390 - val_acc: 0.4695\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.50020\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 7s 748us/step - loss: 6.7157 - acc: 0.4358 - val_loss: 6.1475 - val_acc: 0.5378\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.50020 to 0.53780, saving model to weights-improvement-21-0.54.hdf5\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 6.6824 - acc: 0.4389 - val_loss: 6.2986 - val_acc: 0.4795\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.53780\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 6.6372 - acc: 0.4374 - val_loss: 6.1162 - val_acc: 0.4843\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.53780\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 8s 752us/step - loss: 6.6115 - acc: 0.4374 - val_loss: 6.2731 - val_acc: 0.5133\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.53780\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 8s 759us/step - loss: 6.5554 - acc: 0.4411 - val_loss: 6.0790 - val_acc: 0.5366\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.53780\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 6.5357 - acc: 0.4419 - val_loss: 6.0188 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.53780\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 6.4932 - acc: 0.4378 - val_loss: 6.0892 - val_acc: 0.4910\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.53780\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 6.4708 - acc: 0.4358 - val_loss: 6.1032 - val_acc: 0.4729\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.53780\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 6.4525 - acc: 0.4255 - val_loss: 6.0165 - val_acc: 0.4681\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.53780\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.4239 - acc: 0.4365 - val_loss: 5.9334 - val_acc: 0.5386\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.53780 to 0.53860, saving model to weights-improvement-30-0.54.hdf5\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 8s 766us/step - loss: 6.4064 - acc: 0.4317 - val_loss: 5.8770 - val_acc: 0.5065\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.53860\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 8s 767us/step - loss: 6.3778 - acc: 0.4463 - val_loss: 6.0767 - val_acc: 0.5382\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.53860\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.3623 - acc: 0.4391 - val_loss: 5.9827 - val_acc: 0.4732\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.53860\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 6.3568 - acc: 0.4393 - val_loss: 5.8253 - val_acc: 0.5256\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.53860\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 6.3320 - acc: 0.4349 - val_loss: 5.8414 - val_acc: 0.4922\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.53860\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 6.3135 - acc: 0.4448 - val_loss: 5.8068 - val_acc: 0.5043\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.53860\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 6.3240 - acc: 0.4316 - val_loss: 5.8595 - val_acc: 0.5049\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.53860\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 6.2863 - acc: 0.4344 - val_loss: 5.9634 - val_acc: 0.5169\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.53860\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 6.2785 - acc: 0.4371 - val_loss: 5.8199 - val_acc: 0.4804\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.53860\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 752us/step - loss: 6.2545 - acc: 0.4403 - val_loss: 5.8927 - val_acc: 0.4969\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.53860\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 6.2575 - acc: 0.4401 - val_loss: 6.0695 - val_acc: 0.5156\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.53860\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 6.2570 - acc: 0.4278 - val_loss: 5.8474 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.53860\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 7s 746us/step - loss: 6.2429 - acc: 0.4342 - val_loss: 5.8807 - val_acc: 0.5234\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.53860\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 6.2220 - acc: 0.4367 - val_loss: 5.7816 - val_acc: 0.5068\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.53860\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 6.2424 - acc: 0.4417 - val_loss: 5.8021 - val_acc: 0.5048\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.53860\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 7s 744us/step - loss: 6.2320 - acc: 0.4410 - val_loss: 5.7666 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.53860 to 0.54900, saving model to weights-improvement-46-0.55.hdf5\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 6.2210 - acc: 0.4460 - val_loss: 6.0360 - val_acc: 0.5074\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.54900\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 8s 769us/step - loss: 6.2119 - acc: 0.4443 - val_loss: 5.8936 - val_acc: 0.4993\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.54900\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 8s 763us/step - loss: 6.2004 - acc: 0.4457 - val_loss: 5.8454 - val_acc: 0.5693\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.54900 to 0.56930, saving model to weights-improvement-49-0.57.hdf5\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 8s 765us/step - loss: 6.1994 - acc: 0.4390 - val_loss: 5.7477 - val_acc: 0.4909\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.56930\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 8s 766us/step - loss: 6.2011 - acc: 0.4425 - val_loss: 5.7943 - val_acc: 0.4969\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.56930\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.1887 - acc: 0.4451 - val_loss: 5.7981 - val_acc: 0.5199\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.56930\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 6.1872 - acc: 0.4351 - val_loss: 5.7505 - val_acc: 0.4778\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.56930\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.1799 - acc: 0.4337 - val_loss: 5.7069 - val_acc: 0.5359\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.56930\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 6.1700 - acc: 0.4231 - val_loss: 5.8267 - val_acc: 0.5401\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.56930\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.2104 - acc: 0.4423 - val_loss: 5.8233 - val_acc: 0.5092\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.56930\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 6.1780 - acc: 0.4282 - val_loss: 5.7690 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.56930\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 6.2002 - acc: 0.4465 - val_loss: 5.7695 - val_acc: 0.5181\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.56930\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 8s 765us/step - loss: 6.1791 - acc: 0.4398 - val_loss: 5.7488 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.56930\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 8s 759us/step - loss: 6.1906 - acc: 0.4468 - val_loss: 5.7117 - val_acc: 0.5033\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.56930\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 6.1913 - acc: 0.4462 - val_loss: 5.7590 - val_acc: 0.4930\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.56930\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 8s 753us/step - loss: 6.1620 - acc: 0.4427 - val_loss: 5.6804 - val_acc: 0.4957\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.56930\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 6.1614 - acc: 0.4483 - val_loss: 5.7659 - val_acc: 0.5636\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.56930\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 8s 765us/step - loss: 6.1844 - acc: 0.4453 - val_loss: 5.7823 - val_acc: 0.5315\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.56930\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.1577 - acc: 0.4281 - val_loss: 5.7683 - val_acc: 0.4942\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.56930\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 6.1506 - acc: 0.4330 - val_loss: 5.6663 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.56930\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 8s 753us/step - loss: 6.1626 - acc: 0.4420 - val_loss: 5.7441 - val_acc: 0.5068\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.56930\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.1588 - acc: 0.4417 - val_loss: 5.6783 - val_acc: 0.4788\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.56930\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 6.1582 - acc: 0.4511 - val_loss: 5.6938 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.56930\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 6.1633 - acc: 0.4411 - val_loss: 5.6722 - val_acc: 0.5311\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.56930\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 6.1673 - acc: 0.4462 - val_loss: 5.6714 - val_acc: 0.5019\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.56930\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.1641 - acc: 0.4436 - val_loss: 5.9405 - val_acc: 0.6009\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.56930 to 0.60090, saving model to weights-improvement-72-0.60.hdf5\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 6.1526 - acc: 0.4532 - val_loss: 5.6869 - val_acc: 0.4768\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.60090\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 8s 763us/step - loss: 6.1848 - acc: 0.4342 - val_loss: 5.9058 - val_acc: 0.5356\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.60090\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 6.1546 - acc: 0.4532 - val_loss: 5.6499 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.60090\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 8s 785us/step - loss: 6.1862 - acc: 0.4388 - val_loss: 5.6792 - val_acc: 0.4844\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.60090\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 8s 773us/step - loss: 6.1613 - acc: 0.4344 - val_loss: 5.6889 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.60090\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.1882 - acc: 0.4423 - val_loss: 5.9689 - val_acc: 0.5289\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.60090\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.1483 - acc: 0.4490 - val_loss: 5.6889 - val_acc: 0.5170\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.60090\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 6.1558 - acc: 0.4485 - val_loss: 5.6648 - val_acc: 0.5423\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.60090\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.1886 - acc: 0.4403 - val_loss: 5.6702 - val_acc: 0.4997\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.60090\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 756us/step - loss: 6.1635 - acc: 0.4467 - val_loss: 5.7735 - val_acc: 0.5129\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.60090\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 6.1594 - acc: 0.4397 - val_loss: 5.6669 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.60090\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 6.1493 - acc: 0.4584 - val_loss: 5.7491 - val_acc: 0.5163\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.60090\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 8s 762us/step - loss: 6.1668 - acc: 0.4482 - val_loss: 5.7064 - val_acc: 0.4526\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.60090\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 6.1634 - acc: 0.4398 - val_loss: 5.6713 - val_acc: 0.5259\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.60090\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 6.1732 - acc: 0.4397 - val_loss: 5.6369 - val_acc: 0.4606\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.60090\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 6.1744 - acc: 0.4421 - val_loss: 5.7008 - val_acc: 0.5562\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.60090\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 6.1846 - acc: 0.4499 - val_loss: 5.6596 - val_acc: 0.4689\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.60090\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 8s 765us/step - loss: 6.1775 - acc: 0.4538 - val_loss: 6.1242 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.60090\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 8s 765us/step - loss: 6.1776 - acc: 0.4423 - val_loss: 5.7418 - val_acc: 0.5155\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.60090\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 6.1667 - acc: 0.4525 - val_loss: 6.0381 - val_acc: 0.4640\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.60090\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 7s 745us/step - loss: 6.1693 - acc: 0.4394 - val_loss: 5.7177 - val_acc: 0.4858\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.60090\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 6.1723 - acc: 0.4457 - val_loss: 5.8343 - val_acc: 0.5321\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.60090\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 7s 746us/step - loss: 6.1563 - acc: 0.4484 - val_loss: 5.6648 - val_acc: 0.4816\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.60090\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 7s 747us/step - loss: 6.1789 - acc: 0.4518 - val_loss: 5.7330 - val_acc: 0.5245\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.60090\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 6.1748 - acc: 0.4488 - val_loss: 5.7068 - val_acc: 0.5302\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.60090\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 6.1701 - acc: 0.4539 - val_loss: 5.6388 - val_acc: 0.5062\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.60090\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 6.1611 - acc: 0.4493 - val_loss: 6.3772 - val_acc: 0.5174\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.60090\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 6.1536 - acc: 0.4423 - val_loss: 5.8195 - val_acc: 0.5214\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.60090\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "# Fit the model\n",
    "history = model.fit(train_set,train_label,epochs=100,batch_size=32, callbacks=callbacks_list, validation_data=(val_set,val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 8s 775us/step - loss: 6.1695 - acc: 0.4398 - val_loss: 5.7077 - val_acc: 0.4626\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.46260, saving model to weights-best.hdf5\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 7s 746us/step - loss: 6.1635 - acc: 0.4401 - val_loss: 5.8083 - val_acc: 0.5110\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.46260 to 0.51100, saving model to weights-best.hdf5\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 7s 746us/step - loss: 6.1742 - acc: 0.4513 - val_loss: 5.7989 - val_acc: 0.5354\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.51100 to 0.53540, saving model to weights-best.hdf5\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 6.1863 - acc: 0.4353 - val_loss: 5.6507 - val_acc: 0.4972\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.53540\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 6.1714 - acc: 0.4347 - val_loss: 5.7292 - val_acc: 0.5060\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.53540\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 7s 748us/step - loss: 6.1833 - acc: 0.4406 - val_loss: 6.1816 - val_acc: 0.5478\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.53540 to 0.54780, saving model to weights-best.hdf5\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 6.1616 - acc: 0.4434 - val_loss: 5.6839 - val_acc: 0.4797\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.54780\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 6.1627 - acc: 0.4480 - val_loss: 5.8814 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.54780\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 6.1704 - acc: 0.4394 - val_loss: 5.7361 - val_acc: 0.4961\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.54780\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 8s 765us/step - loss: 6.1652 - acc: 0.4589 - val_loss: 5.7215 - val_acc: 0.5110\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.54780\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('weights-improvement-72-0.60.hdf5')\n",
    "\n",
    "filepath=\"weights-best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#Continue training\n",
    "history = model.fit(train_set,train_label,epochs=10,batch_size=32, callbacks=callbacks_list, validation_data=(val_set,val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(base_dir, 'test')\n",
    "test_set = np.ndarray(shape=(train_num, IMAGE_HEIGHT, IMAGE_WIDTH),dtype=np.float32)\n",
    "test_label = np.ndarray(shape=(train_num, MAXLABEL),dtype=np.float32)\n",
    "test_num = 10000\n",
    "for i in range(test_num) :\n",
    "    fname = '{}.png'.format(i)\n",
    "    file = os.path.join(test_dir,fname)\n",
    "    img = image.load_img(file, target_size=(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "    arr = np.asarray(img,dtype=\"float32\")/255.0\n",
    "    arr = convert2gray(arr)\n",
    "    test_set[i] = arr    \n",
    "    test_label[i] = num2vec(i)\n",
    "\n",
    "test_set = test_set.reshape((test_num,IMAGE_HEIGHT, IMAGE_WIDTH,1))\n",
    "real_label = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 5, 4], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alabel = real_label[4535].reshape(4,10)\n",
    "alabel.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
