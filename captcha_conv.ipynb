{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.Session(config=config)\n",
    "\n",
    "base_dir = 'D:\\src\\captchagen\\out'\n",
    "rerun_0 = 0\n",
    "rerun_1 = 1\n",
    "\n",
    "IMAGE_HEIGHT = 60\n",
    "IMAGE_WIDTH = 180\n",
    "MAX_NUM_LEN = 10000\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "def convert2gray(img):\n",
    "    if len(img.shape) > 2:\n",
    "        gray = np.mean(img, -1)\n",
    "        return gray\n",
    "    else:\n",
    "        return img\n",
    "    \n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "MAXLABEL = 40\n",
    "def num2vec(num):\n",
    "    if num < 0 or num > 9999 :\n",
    "        raise ValueError('number not in range 0-9999')\n",
    "    vector = np.zeros(MAXLABEL)\n",
    "    i = 0\n",
    "    while int(num) > 0:\n",
    "        idx = i * 10 + int(num) % 10\n",
    "        #print(idx)\n",
    "        num /= 10\n",
    "        i += 1\n",
    "        vector[idx] = 1 \n",
    "    return vector\n",
    "\n",
    "train_num = 10000\n",
    "\n",
    "train_set = np.ndarray(shape=(train_num, IMAGE_HEIGHT, IMAGE_WIDTH),dtype=np.float32)\n",
    "train_label = np.ndarray(shape=(train_num, MAXLABEL),dtype=np.float32)\n",
    "\n",
    "for i in range(train_num) :\n",
    "    fname = '{}.png'.format(i)\n",
    "    file = os.path.join(train_dir,fname)\n",
    "    img = image.load_img(file, target_size=(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "    arr = np.asarray(img,dtype=\"float32\")/255.0\n",
    "    arr = convert2gray(arr)\n",
    "    train_set[i] = arr    \n",
    "    train_label[i] = num2vec(i)\n",
    "\n",
    "val_num = 10000\n",
    "val_set = np.ndarray(shape=(val_num, IMAGE_HEIGHT, IMAGE_WIDTH),dtype=np.float32)\n",
    "val_label = np.ndarray(shape=(val_num, MAXLABEL),dtype=np.float32)\n",
    "\n",
    "for i in range(val_num) :\n",
    "    fname = '{}.png'.format(i)\n",
    "    file = os.path.join(validation_dir,fname)\n",
    "    img = image.load_img(file, target_size=(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "    arr = np.asarray(img,dtype=\"float32\")/255.0\n",
    "    arr = convert2gray(arr)\n",
    "    val_set[i] = arr    \n",
    "    val_label[i] = num2vec(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "imgplot = plt.imshow(image.array_to_img(val_set[22].reshape(IMAGE_HEIGHT,IMAGE_WIDTH,1)))\n",
    "plt.figure(2)\n",
    "imgplot = plt.imshow(image.array_to_img(train_set[22].reshape(IMAGE_HEIGHT,IMAGE_WIDTH,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 40)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set.shape\n",
    "val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 60, 180, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = train_set.reshape((train_num,IMAGE_HEIGHT, IMAGE_WIDTH,1))\n",
    "val_set = val_set.reshape((val_num,IMAGE_HEIGHT, IMAGE_WIDTH,1))\n",
    "\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_79 (Conv2D)           (None, 58, 178, 64)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 29, 89, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 27, 87, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 13, 43, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 11, 41, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 5, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 3, 18, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 1, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 40)                2600      \n",
      "=================================================================\n",
      "Total params: 1,847,400\n",
      "Trainable params: 1,847,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "#from keras.applications import VGG16\n",
    "\n",
    "#conv_base = VGG16(weights='imagenet',\n",
    "#                 include_top=False,\n",
    "#                 input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH,3))\n",
    "\n",
    "#conv_base.summary()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu', input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH,1)))\n",
    "#model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
    "#model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "#model.add(layers.Conv2D(256,(3,3), activation='relu'))\n",
    "model.add(layers.Conv2D(256,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(512,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#conv_base.trainable = False\n",
    "#model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense (64, activation = 'relu'))\n",
    "model.add(layers.Dense (40, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer= 'adadelta',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10000\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 14.2745 - acc: 0.0172 - val_loss: 14.2578 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.00000, saving model to D:\\src\\weights-improvement-01-0.00.hdf5\n",
      "Epoch 2/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 14.2544 - acc: 0.0267 - val_loss: 14.2504 - val_acc: 0.1000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.00000 to 0.10000, saving model to D:\\src\\weights-improvement-02-0.10.hdf5\n",
      "Epoch 3/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 14.2514 - acc: 0.0302 - val_loss: 14.2479 - val_acc: 1.0000e-03\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.10000\n",
      "Epoch 4/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 14.2455 - acc: 0.0265 - val_loss: 14.2324 - val_acc: 0.0223\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.10000\n",
      "Epoch 5/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 14.0619 - acc: 0.0255 - val_loss: 13.6901 - val_acc: 0.0500\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.10000\n",
      "Epoch 6/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 12.6496 - acc: 0.1242 - val_loss: 11.4467 - val_acc: 0.1686\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.10000 to 0.16860, saving model to D:\\src\\weights-improvement-06-0.17.hdf5\n",
      "Epoch 7/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 10.2222 - acc: 0.2551 - val_loss: 8.9646 - val_acc: 0.2887\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.16860 to 0.28870, saving model to D:\\src\\weights-improvement-07-0.29.hdf5\n",
      "Epoch 8/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 8.1318 - acc: 0.3214 - val_loss: 7.6285 - val_acc: 0.3210\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.28870 to 0.32100, saving model to D:\\src\\weights-improvement-08-0.32.hdf5\n",
      "Epoch 9/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 7.0978 - acc: 0.3520 - val_loss: 7.0229 - val_acc: 0.3702\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.32100 to 0.37020, saving model to D:\\src\\weights-improvement-09-0.37.hdf5\n",
      "Epoch 10/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 6.5629 - acc: 0.3630 - val_loss: 6.6766 - val_acc: 0.3642\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.37020\n",
      "Epoch 11/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 6.2545 - acc: 0.3667 - val_loss: 6.3423 - val_acc: 0.4154\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.37020 to 0.41540, saving model to D:\\src\\weights-improvement-11-0.42.hdf5\n",
      "Epoch 12/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 6.0279 - acc: 0.3713 - val_loss: 6.2765 - val_acc: 0.3945\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.41540\n",
      "Epoch 13/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.8851 - acc: 0.3726 - val_loss: 6.1536 - val_acc: 0.4115\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.41540\n",
      "Epoch 14/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.7741 - acc: 0.3889 - val_loss: 6.2013 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.41540\n",
      "Epoch 15/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.6949 - acc: 0.3791 - val_loss: 6.1006 - val_acc: 0.3940\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.41540\n",
      "Epoch 16/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.6344 - acc: 0.3906 - val_loss: 6.0178 - val_acc: 0.3354\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.41540\n",
      "Epoch 17/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5918 - acc: 0.3819 - val_loss: 5.9411 - val_acc: 0.4079\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.41540\n",
      "Epoch 18/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5393 - acc: 0.3786 - val_loss: 6.0073 - val_acc: 0.3654\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.41540\n",
      "Epoch 19/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5176 - acc: 0.3797 - val_loss: 6.0908 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.41540\n",
      "Epoch 20/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5013 - acc: 0.4015 - val_loss: 5.9730 - val_acc: 0.3894\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.41540\n",
      "Epoch 21/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4853 - acc: 0.4234 - val_loss: 5.8992 - val_acc: 0.4119\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.41540\n",
      "Epoch 22/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4692 - acc: 0.4164 - val_loss: 5.7507 - val_acc: 0.4020\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.41540\n",
      "Epoch 23/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4547 - acc: 0.4104 - val_loss: 5.9049 - val_acc: 0.4028\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.41540\n",
      "Epoch 24/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4426 - acc: 0.4113 - val_loss: 5.7775 - val_acc: 0.4312\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.41540 to 0.43120, saving model to D:\\src\\weights-improvement-24-0.43.hdf5\n",
      "Epoch 25/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4375 - acc: 0.4226 - val_loss: 5.8861 - val_acc: 0.4014\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.43120\n",
      "Epoch 26/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4258 - acc: 0.4194 - val_loss: 5.8151 - val_acc: 0.4526\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.43120 to 0.45260, saving model to D:\\src\\weights-improvement-26-0.45.hdf5\n",
      "Epoch 27/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4190 - acc: 0.4242 - val_loss: 5.8422 - val_acc: 0.4023\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.45260\n",
      "Epoch 28/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4310 - acc: 0.4386 - val_loss: 5.7733 - val_acc: 0.4637\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.45260 to 0.46370, saving model to D:\\src\\weights-improvement-28-0.46.hdf5\n",
      "Epoch 29/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4170 - acc: 0.4371 - val_loss: 5.7628 - val_acc: 0.4959\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.46370 to 0.49590, saving model to D:\\src\\weights-improvement-29-0.50.hdf5\n",
      "Epoch 30/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4169 - acc: 0.4280 - val_loss: 5.8928 - val_acc: 0.4451\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.49590\n",
      "Epoch 31/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4109 - acc: 0.4555 - val_loss: 5.8168 - val_acc: 0.4248\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.49590\n",
      "Epoch 32/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4042 - acc: 0.4562 - val_loss: 5.8572 - val_acc: 0.4674\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.49590\n",
      "Epoch 33/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4042 - acc: 0.4541 - val_loss: 5.7732 - val_acc: 0.4838\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.49590\n",
      "Epoch 34/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4106 - acc: 0.4502 - val_loss: 5.8266 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.49590\n",
      "Epoch 35/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4085 - acc: 0.4453 - val_loss: 5.7043 - val_acc: 0.3902\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.49590\n",
      "Epoch 36/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4066 - acc: 0.4254 - val_loss: 5.7919 - val_acc: 0.4797\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.49590\n",
      "Epoch 37/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4143 - acc: 0.4473 - val_loss: 5.7091 - val_acc: 0.4634\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.49590\n",
      "Epoch 38/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4126 - acc: 0.4698 - val_loss: 5.7287 - val_acc: 0.4052\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.49590\n",
      "Epoch 39/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4085 - acc: 0.4724 - val_loss: 5.7683 - val_acc: 0.5209\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.49590 to 0.52090, saving model to D:\\src\\weights-improvement-39-0.52.hdf5\n",
      "Epoch 40/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4149 - acc: 0.4665 - val_loss: 5.7265 - val_acc: 0.5188\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.52090\n",
      "Epoch 41/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4045 - acc: 0.4719 - val_loss: 5.8133 - val_acc: 0.5098\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.52090\n",
      "Epoch 42/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4144 - acc: 0.4766 - val_loss: 5.6713 - val_acc: 0.5430\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.52090 to 0.54300, saving model to D:\\src\\weights-improvement-42-0.54.hdf5\n",
      "Epoch 43/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4074 - acc: 0.4723 - val_loss: 5.6470 - val_acc: 0.4755\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.54300\n",
      "Epoch 44/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4108 - acc: 0.4575 - val_loss: 5.7722 - val_acc: 0.4370\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.54300\n",
      "Epoch 45/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4136 - acc: 0.4889 - val_loss: 5.6246 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.54300\n",
      "Epoch 46/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4113 - acc: 0.5001 - val_loss: 5.8260 - val_acc: 0.4848\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.54300\n",
      "Epoch 47/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4095 - acc: 0.4879 - val_loss: 5.8189 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.54300\n",
      "Epoch 48/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 5.4129 - acc: 0.5011 - val_loss: 5.6674 - val_acc: 0.5371\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.54300\n",
      "Epoch 49/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4163 - acc: 0.5045 - val_loss: 5.8427 - val_acc: 0.5141\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.54300\n",
      "Epoch 50/10000\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 5.4167 - acc: 0.4834 - val_loss: 5.7656 - val_acc: 0.4208\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.54300\n",
      "Epoch 51/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 5.4078 - acc: 0.5002 - val_loss: 5.7823 - val_acc: 0.6130\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.54300 to 0.61300, saving model to D:\\src\\weights-improvement-51-0.61.hdf5\n",
      "Epoch 52/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4063 - acc: 0.5146 - val_loss: 5.6605 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.61300\n",
      "Epoch 53/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4117 - acc: 0.5385 - val_loss: 5.6721 - val_acc: 0.4911\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.61300\n",
      "Epoch 54/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4070 - acc: 0.4925 - val_loss: 5.7475 - val_acc: 0.4674\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.61300\n",
      "Epoch 55/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4229 - acc: 0.5007 - val_loss: 5.8008 - val_acc: 0.5221\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.61300\n",
      "Epoch 56/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4122 - acc: 0.5351 - val_loss: 5.6865 - val_acc: 0.6644\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.61300 to 0.66440, saving model to D:\\src\\weights-improvement-56-0.66.hdf5\n",
      "Epoch 57/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4102 - acc: 0.5238 - val_loss: 5.8039 - val_acc: 0.5169\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.66440\n",
      "Epoch 58/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4126 - acc: 0.5298 - val_loss: 5.6419 - val_acc: 0.6137\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.66440\n",
      "Epoch 59/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4141 - acc: 0.5386 - val_loss: 5.8357 - val_acc: 0.5728\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.66440\n",
      "Epoch 60/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4282 - acc: 0.5444 - val_loss: 5.6643 - val_acc: 0.5463\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.66440\n",
      "Epoch 61/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4189 - acc: 0.5246 - val_loss: 5.7012 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.66440\n",
      "Epoch 62/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4259 - acc: 0.5587 - val_loss: 5.5952 - val_acc: 0.5511\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.66440\n",
      "Epoch 63/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4096 - acc: 0.5384 - val_loss: 6.0377 - val_acc: 0.5527\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.66440\n",
      "Epoch 64/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4123 - acc: 0.5372 - val_loss: 5.6398 - val_acc: 0.6014\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.66440\n",
      "Epoch 65/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4102 - acc: 0.5577 - val_loss: 5.7596 - val_acc: 0.5768\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.66440\n",
      "Epoch 66/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4121 - acc: 0.5595 - val_loss: 5.7108 - val_acc: 0.5862\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.66440\n",
      "Epoch 67/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4043 - acc: 0.5456 - val_loss: 5.9861 - val_acc: 0.5129\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.66440\n",
      "Epoch 68/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4239 - acc: 0.5463 - val_loss: 5.6606 - val_acc: 0.5884\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.66440\n",
      "Epoch 69/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4142 - acc: 0.5279 - val_loss: 5.7039 - val_acc: 0.5910\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.66440\n",
      "Epoch 70/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4122 - acc: 0.5174 - val_loss: 5.7055 - val_acc: 0.6042\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.66440\n",
      "Epoch 71/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4111 - acc: 0.5659 - val_loss: 5.7042 - val_acc: 0.6259\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.66440\n",
      "Epoch 72/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4022 - acc: 0.5780 - val_loss: 5.6995 - val_acc: 0.5504\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.66440\n",
      "Epoch 73/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4147 - acc: 0.6102 - val_loss: 5.6954 - val_acc: 0.6194\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.66440\n",
      "Epoch 74/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4097 - acc: 0.5686 - val_loss: 5.7690 - val_acc: 0.5984\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.66440\n",
      "Epoch 75/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4121 - acc: 0.5821 - val_loss: 5.7620 - val_acc: 0.5772\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.66440\n",
      "Epoch 76/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3997 - acc: 0.6001 - val_loss: 5.7312 - val_acc: 0.6106\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.66440\n",
      "Epoch 77/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4060 - acc: 0.5946 - val_loss: 5.7292 - val_acc: 0.5696\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.66440\n",
      "Epoch 78/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4074 - acc: 0.6137 - val_loss: 5.7399 - val_acc: 0.6168\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.66440\n",
      "Epoch 79/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4027 - acc: 0.6119 - val_loss: 5.7971 - val_acc: 0.5602\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.66440\n",
      "Epoch 80/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4002 - acc: 0.6044 - val_loss: 5.7508 - val_acc: 0.5278\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.66440\n",
      "Epoch 81/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4024 - acc: 0.6155 - val_loss: 5.6694 - val_acc: 0.5917\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.66440\n",
      "Epoch 82/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4024 - acc: 0.5906 - val_loss: 5.6944 - val_acc: 0.6064\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.66440\n",
      "Epoch 83/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4064 - acc: 0.5914 - val_loss: 5.6461 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.66440 to 0.67050, saving model to D:\\src\\weights-improvement-83-0.67.hdf5\n",
      "Epoch 84/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3932 - acc: 0.6292 - val_loss: 6.0218 - val_acc: 0.5458\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.67050\n",
      "Epoch 85/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4090 - acc: 0.6012 - val_loss: 5.6991 - val_acc: 0.5560\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.67050\n",
      "Epoch 86/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3916 - acc: 0.5948 - val_loss: 5.6536 - val_acc: 0.6267\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.67050\n",
      "Epoch 87/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4072 - acc: 0.6125 - val_loss: 5.7272 - val_acc: 0.5266\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.67050\n",
      "Epoch 88/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3961 - acc: 0.6159 - val_loss: 5.8089 - val_acc: 0.6436\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.67050\n",
      "Epoch 89/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4009 - acc: 0.6396 - val_loss: 5.6981 - val_acc: 0.6468\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.67050\n",
      "Epoch 90/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4031 - acc: 0.6663 - val_loss: 5.7385 - val_acc: 0.5940\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.67050\n",
      "Epoch 91/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4005 - acc: 0.6596 - val_loss: 5.7340 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.67050\n",
      "Epoch 92/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4072 - acc: 0.6622 - val_loss: 5.6454 - val_acc: 0.6034\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.67050\n",
      "Epoch 93/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4020 - acc: 0.6644 - val_loss: 5.6583 - val_acc: 0.6688\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.67050\n",
      "Epoch 94/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4047 - acc: 0.6655 - val_loss: 5.6372 - val_acc: 0.6660\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.67050\n",
      "Epoch 95/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3916 - acc: 0.6722 - val_loss: 5.6691 - val_acc: 0.7253\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.67050 to 0.72530, saving model to D:\\src\\weights-improvement-95-0.73.hdf5\n",
      "Epoch 96/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4052 - acc: 0.6604 - val_loss: 5.7217 - val_acc: 0.6708\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.72530\n",
      "Epoch 97/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3918 - acc: 0.6782 - val_loss: 5.8200 - val_acc: 0.7184\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.72530\n",
      "Epoch 98/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4060 - acc: 0.7069 - val_loss: 5.6679 - val_acc: 0.7560\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.72530 to 0.75600, saving model to D:\\src\\weights-improvement-98-0.76.hdf5\n",
      "Epoch 99/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4026 - acc: 0.7056 - val_loss: 6.2243 - val_acc: 0.5111\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.75600\n",
      "Epoch 100/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4094 - acc: 0.6781 - val_loss: 5.6908 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.75600\n",
      "Epoch 101/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4151 - acc: 0.6912 - val_loss: 6.0160 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.75600\n",
      "Epoch 102/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4022 - acc: 0.6762 - val_loss: 5.7575 - val_acc: 0.6636\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.75600\n",
      "Epoch 103/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4189 - acc: 0.6981 - val_loss: 5.6544 - val_acc: 0.7349\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.75600\n",
      "Epoch 104/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4012 - acc: 0.7077 - val_loss: 6.5164 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.75600\n",
      "Epoch 105/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4079 - acc: 0.7019 - val_loss: 5.9085 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.75600\n",
      "Epoch 106/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3947 - acc: 0.7167 - val_loss: 5.6767 - val_acc: 0.7313\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.75600\n",
      "Epoch 107/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4027 - acc: 0.7111 - val_loss: 5.6254 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.75600\n",
      "Epoch 108/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4172 - acc: 0.7382 - val_loss: 5.7331 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.75600\n",
      "Epoch 109/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4059 - acc: 0.7124 - val_loss: 5.7042 - val_acc: 0.6944\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.75600\n",
      "Epoch 110/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4085 - acc: 0.7260 - val_loss: 5.6553 - val_acc: 0.7762\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.75600 to 0.77620, saving model to D:\\src\\weights-improvement-110-0.78.hdf5\n",
      "Epoch 111/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3987 - acc: 0.7303 - val_loss: 5.6349 - val_acc: 0.8261\n",
      "\n",
      "Epoch 00111: val_acc improved from 0.77620 to 0.82610, saving model to D:\\src\\weights-improvement-111-0.83.hdf5\n",
      "Epoch 112/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3976 - acc: 0.7358 - val_loss: 5.6423 - val_acc: 0.7060\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.82610\n",
      "Epoch 113/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4003 - acc: 0.7317 - val_loss: 5.6798 - val_acc: 0.6986\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.82610\n",
      "Epoch 114/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3959 - acc: 0.7222 - val_loss: 5.7006 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.82610\n",
      "Epoch 115/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4038 - acc: 0.7250 - val_loss: 5.7214 - val_acc: 0.7120\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.82610\n",
      "Epoch 116/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4039 - acc: 0.7110 - val_loss: 5.6484 - val_acc: 0.7615\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.82610\n",
      "Epoch 117/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3923 - acc: 0.7271 - val_loss: 5.6803 - val_acc: 0.7301\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.82610\n",
      "Epoch 118/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3969 - acc: 0.7398 - val_loss: 5.7702 - val_acc: 0.7343\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.82610\n",
      "Epoch 119/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4102 - acc: 0.7468 - val_loss: 5.9861 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.82610\n",
      "Epoch 120/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3961 - acc: 0.7427 - val_loss: 5.7109 - val_acc: 0.6887\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.82610\n",
      "Epoch 121/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4071 - acc: 0.7573 - val_loss: 5.6575 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.82610\n",
      "Epoch 122/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4041 - acc: 0.7532 - val_loss: 5.7694 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.82610\n",
      "Epoch 123/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3987 - acc: 0.7554 - val_loss: 5.8184 - val_acc: 0.7504\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.82610\n",
      "Epoch 124/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 5.3933 - acc: 0.7842 - val_loss: 5.8068 - val_acc: 0.8142\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.82610\n",
      "Epoch 125/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4049 - acc: 0.7755 - val_loss: 5.6944 - val_acc: 0.7029\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.82610\n",
      "Epoch 126/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4108 - acc: 0.7805 - val_loss: 5.6829 - val_acc: 0.8338\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.82610 to 0.83380, saving model to D:\\src\\weights-improvement-126-0.83.hdf5\n",
      "Epoch 127/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4109 - acc: 0.7749 - val_loss: 5.7555 - val_acc: 0.8336\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.83380\n",
      "Epoch 128/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4092 - acc: 0.7793 - val_loss: 6.0200 - val_acc: 0.7739\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.83380\n",
      "Epoch 129/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4155 - acc: 0.7874 - val_loss: 5.9916 - val_acc: 0.8124\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.83380\n",
      "Epoch 130/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4145 - acc: 0.8007 - val_loss: 5.7356 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.83380\n",
      "Epoch 131/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4092 - acc: 0.7839 - val_loss: 5.6338 - val_acc: 0.8361\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.83380 to 0.83610, saving model to D:\\src\\weights-improvement-131-0.84.hdf5\n",
      "Epoch 132/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 5.4046 - acc: 0.8040 - val_loss: 5.7854 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.83610\n",
      "Epoch 133/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4130 - acc: 0.7868 - val_loss: 5.8654 - val_acc: 0.8188\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.83610\n",
      "Epoch 134/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4152 - acc: 0.7960 - val_loss: 5.7864 - val_acc: 0.7590\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.83610\n",
      "Epoch 135/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4026 - acc: 0.8014 - val_loss: 5.7145 - val_acc: 0.8058\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.83610\n",
      "Epoch 136/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3956 - acc: 0.8134 - val_loss: 5.6837 - val_acc: 0.8015\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.83610\n",
      "Epoch 137/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3936 - acc: 0.7963 - val_loss: 6.0684 - val_acc: 0.7337\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.83610\n",
      "Epoch 138/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4081 - acc: 0.8169 - val_loss: 5.7399 - val_acc: 0.8212\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.83610\n",
      "Epoch 139/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4122 - acc: 0.8043 - val_loss: 6.2127 - val_acc: 0.8175\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.83610\n",
      "Epoch 140/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.3943 - acc: 0.8244 - val_loss: 6.2160 - val_acc: 0.8202\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.83610\n",
      "Epoch 141/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4212 - acc: 0.8133 - val_loss: 5.7298 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.83610\n",
      "Epoch 142/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4012 - acc: 0.8081 - val_loss: 5.7091 - val_acc: 0.8102\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.83610\n",
      "Epoch 143/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4071 - acc: 0.8229 - val_loss: 5.8507 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.83610\n",
      "Epoch 144/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4201 - acc: 0.8210 - val_loss: 5.6830 - val_acc: 0.8202\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.83610\n",
      "Epoch 145/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4090 - acc: 0.8111 - val_loss: 5.8886 - val_acc: 0.7581\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.83610\n",
      "Epoch 146/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4051 - acc: 0.8202 - val_loss: 5.8010 - val_acc: 0.8353\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.83610\n",
      "Epoch 147/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4223 - acc: 0.8076 - val_loss: 5.7771 - val_acc: 0.7845\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.83610\n",
      "Epoch 148/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4036 - acc: 0.8215 - val_loss: 5.8130 - val_acc: 0.8079\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.83610\n",
      "Epoch 149/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4333 - acc: 0.7991 - val_loss: 5.7012 - val_acc: 0.7472\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.83610\n",
      "Epoch 150/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4206 - acc: 0.8203 - val_loss: 5.7398 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.83610 to 0.84760, saving model to D:\\src\\weights-improvement-150-0.85.hdf5\n",
      "Epoch 151/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4126 - acc: 0.8350 - val_loss: 5.7055 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.84760\n",
      "Epoch 152/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4395 - acc: 0.8260 - val_loss: 5.7839 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.84760 to 0.85560, saving model to D:\\src\\weights-improvement-152-0.86.hdf5\n",
      "Epoch 153/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4207 - acc: 0.8175 - val_loss: 5.7894 - val_acc: 0.8150\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.85560\n",
      "Epoch 154/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4184 - acc: 0.8339 - val_loss: 6.1342 - val_acc: 0.7133\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.85560\n",
      "Epoch 155/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4214 - acc: 0.8501 - val_loss: 5.6916 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.85560\n",
      "Epoch 156/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4135 - acc: 0.8400 - val_loss: 5.7223 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.85560\n",
      "Epoch 157/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4366 - acc: 0.8270 - val_loss: 5.7843 - val_acc: 0.7355\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.85560\n",
      "Epoch 158/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4268 - acc: 0.8528 - val_loss: 5.6482 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.85560\n",
      "Epoch 159/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4171 - acc: 0.8596 - val_loss: 6.2605 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.85560\n",
      "Epoch 160/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4215 - acc: 0.8305 - val_loss: 6.0075 - val_acc: 0.8231\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.85560\n",
      "Epoch 161/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4288 - acc: 0.8476 - val_loss: 5.9421 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00161: val_acc improved from 0.85560 to 0.87840, saving model to D:\\src\\weights-improvement-161-0.88.hdf5\n",
      "Epoch 162/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4223 - acc: 0.8658 - val_loss: 5.8282 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.87840\n",
      "Epoch 163/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4156 - acc: 0.8661 - val_loss: 5.9645 - val_acc: 0.8010\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.87840\n",
      "Epoch 164/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4290 - acc: 0.8694 - val_loss: 5.8265 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.87840 to 0.88130, saving model to D:\\src\\weights-improvement-164-0.88.hdf5\n",
      "Epoch 165/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4128 - acc: 0.8878 - val_loss: 5.8517 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.88130\n",
      "Epoch 166/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4235 - acc: 0.8687 - val_loss: 5.8471 - val_acc: 0.8186\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.88130\n",
      "Epoch 167/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4276 - acc: 0.8797 - val_loss: 6.0428 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.88130\n",
      "Epoch 168/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4316 - acc: 0.8925 - val_loss: 5.8079 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.88130\n",
      "Epoch 169/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4218 - acc: 0.8648 - val_loss: 5.7851 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.88130\n",
      "Epoch 170/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4082 - acc: 0.8786 - val_loss: 5.9778 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.88130\n",
      "Epoch 171/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4214 - acc: 0.8819 - val_loss: 6.3905 - val_acc: 0.8153\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.88130\n",
      "Epoch 172/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4272 - acc: 0.8844 - val_loss: 6.0957 - val_acc: 0.8970\n",
      "\n",
      "Epoch 00172: val_acc improved from 0.88130 to 0.89700, saving model to D:\\src\\weights-improvement-172-0.90.hdf5\n",
      "Epoch 173/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4465 - acc: 0.8870 - val_loss: 5.8324 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00173: val_acc improved from 0.89700 to 0.92070, saving model to D:\\src\\weights-improvement-173-0.92.hdf5\n",
      "Epoch 174/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4482 - acc: 0.8996 - val_loss: 5.8970 - val_acc: 0.8534\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.92070\n",
      "Epoch 175/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4502 - acc: 0.9005 - val_loss: 6.0350 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.92070\n",
      "Epoch 176/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4591 - acc: 0.9000 - val_loss: 5.7613 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.92070\n",
      "Epoch 177/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4549 - acc: 0.8944 - val_loss: 5.9231 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.92070\n",
      "Epoch 178/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4295 - acc: 0.9048 - val_loss: 5.8084 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.92070\n",
      "Epoch 179/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4430 - acc: 0.9181 - val_loss: 6.0178 - val_acc: 0.9019\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.92070\n",
      "Epoch 180/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4392 - acc: 0.9170 - val_loss: 5.8923 - val_acc: 0.8965\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.92070\n",
      "Epoch 181/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4415 - acc: 0.9156 - val_loss: 5.9297 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.92070\n",
      "Epoch 182/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4577 - acc: 0.9098 - val_loss: 5.9557 - val_acc: 0.8982\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.92070\n",
      "Epoch 183/10000\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 5.4681 - acc: 0.9203 - val_loss: 5.8890 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.92070\n",
      "Epoch 184/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4664 - acc: 0.9195 - val_loss: 5.8694 - val_acc: 0.9310\n",
      "\n",
      "Epoch 00184: val_acc improved from 0.92070 to 0.93100, saving model to D:\\src\\weights-improvement-184-0.93.hdf5\n",
      "Epoch 185/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4631 - acc: 0.9199 - val_loss: 6.0693 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.93100\n",
      "Epoch 186/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 5.4402 - acc: 0.9218 - val_loss: 5.9891 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.93100\n",
      "Epoch 187/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4653 - acc: 0.9085 - val_loss: 5.9160 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.93100\n",
      "Epoch 188/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4615 - acc: 0.9295 - val_loss: 6.1438 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.93100\n",
      "Epoch 189/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4753 - acc: 0.9176 - val_loss: 5.7774 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.93100\n",
      "Epoch 190/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4799 - acc: 0.9129 - val_loss: 6.0184 - val_acc: 0.9024\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.93100\n",
      "Epoch 191/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4745 - acc: 0.9201 - val_loss: 6.3154 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.93100\n",
      "Epoch 192/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 5.4755 - acc: 0.9299 - val_loss: 5.8898 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.93100\n",
      "Epoch 193/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4706 - acc: 0.9383 - val_loss: 5.8427 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.93100\n",
      "Epoch 194/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4780 - acc: 0.9178 - val_loss: 5.9673 - val_acc: 0.8821\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.93100\n",
      "Epoch 195/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4688 - acc: 0.9302 - val_loss: 5.9008 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.93100\n",
      "Epoch 196/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4888 - acc: 0.9298 - val_loss: 5.7664 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.93100\n",
      "Epoch 197/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4564 - acc: 0.9374 - val_loss: 5.8021 - val_acc: 0.9112\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.93100\n",
      "Epoch 198/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4895 - acc: 0.9354 - val_loss: 5.8556 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.93100\n",
      "Epoch 199/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4811 - acc: 0.9317 - val_loss: 6.0090 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.93100\n",
      "Epoch 200/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4965 - acc: 0.9298 - val_loss: 5.8341 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.93100\n",
      "Epoch 201/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4935 - acc: 0.9377 - val_loss: 6.0691 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.93100\n",
      "Epoch 202/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.4999 - acc: 0.9381 - val_loss: 6.0900 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00202: val_acc improved from 0.93100 to 0.93600, saving model to D:\\src\\weights-improvement-202-0.94.hdf5\n",
      "Epoch 203/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5079 - acc: 0.9324 - val_loss: 6.0111 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.93600\n",
      "Epoch 204/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5066 - acc: 0.9320 - val_loss: 8.7843 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.93600\n",
      "Epoch 205/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5089 - acc: 0.9410 - val_loss: 5.8902 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00205: val_acc improved from 0.93600 to 0.96100, saving model to D:\\src\\weights-improvement-205-0.96.hdf5\n",
      "Epoch 206/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5105 - acc: 0.9431 - val_loss: 6.1643 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.96100\n",
      "Epoch 207/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5382 - acc: 0.9433 - val_loss: 6.1516 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.96100\n",
      "Epoch 208/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5048 - acc: 0.9353 - val_loss: 6.0631 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.96100\n",
      "Epoch 209/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5265 - acc: 0.9419 - val_loss: 5.9849 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.96100\n",
      "Epoch 210/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5419 - acc: 0.9445 - val_loss: 6.1137 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.96100\n",
      "Epoch 211/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 5.4975 - acc: 0.9402 - val_loss: 6.0910 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.96100\n",
      "Epoch 212/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5365 - acc: 0.9474 - val_loss: 5.9178 - val_acc: 0.9520\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.96100\n",
      "Epoch 213/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 5.5339 - acc: 0.9496 - val_loss: 6.1146 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.96100\n",
      "Epoch 214/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5542 - acc: 0.9455 - val_loss: 6.1005 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.96100\n",
      "Epoch 215/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5332 - acc: 0.9525 - val_loss: 5.8952 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.96100\n",
      "Epoch 216/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5566 - acc: 0.9519 - val_loss: 5.9456 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.96100\n",
      "Epoch 217/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5645 - acc: 0.9570 - val_loss: 5.8707 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.96100\n",
      "Epoch 218/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5971 - acc: 0.9499 - val_loss: 6.3717 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.96100\n",
      "Epoch 219/10000\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 5.5405 - acc: 0.9576 - val_loss: 5.9815 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.96100\n",
      "Epoch 220/10000\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 5.5650 - acc: 0.9579 - val_loss: 6.2738 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.96100\n",
      "Epoch 221/10000\n",
      "10000/10000 [==============================] - 53s 5ms/step - loss: 5.5535 - acc: 0.9575 - val_loss: 6.0170 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.96100\n",
      "Epoch 222/10000\n",
      "10000/10000 [==============================] - 52s 5ms/step - loss: 5.5704 - acc: 0.9578 - val_loss: 6.2175 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.96100\n",
      "Epoch 223/10000\n",
      "10000/10000 [==============================] - 52s 5ms/step - loss: 5.6097 - acc: 0.9567 - val_loss: 6.1335 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.96100\n",
      "Epoch 224/10000\n",
      "10000/10000 [==============================] - 53s 5ms/step - loss: 5.5728 - acc: 0.9595 - val_loss: 6.0541 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.96100\n",
      "Epoch 225/10000\n",
      "10000/10000 [==============================] - 53s 5ms/step - loss: 5.5917 - acc: 0.9568 - val_loss: 6.3702 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.96100\n",
      "Epoch 226/10000\n",
      "10000/10000 [==============================] - 170s 17ms/step - loss: 5.6211 - acc: 0.9606 - val_loss: 6.0030 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00226: val_acc improved from 0.96100 to 0.96510, saving model to D:\\src\\weights-improvement-226-0.97.hdf5\n",
      "Epoch 227/10000\n",
      "10000/10000 [==============================] - 186s 19ms/step - loss: 5.6018 - acc: 0.9673 - val_loss: 6.0519 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.96510\n",
      "Epoch 228/10000\n",
      "10000/10000 [==============================] - 180s 18ms/step - loss: 5.6184 - acc: 0.9682 - val_loss: 6.4800 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.96510\n",
      "Epoch 229/10000\n",
      "10000/10000 [==============================] - 188s 19ms/step - loss: 5.6353 - acc: 0.9653 - val_loss: 5.9740 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.96510\n",
      "Epoch 230/10000\n",
      "10000/10000 [==============================] - 204s 20ms/step - loss: 5.6703 - acc: 0.9646 - val_loss: 6.1955 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.96510\n",
      "Epoch 231/10000\n",
      "10000/10000 [==============================] - 179s 18ms/step - loss: 5.6777 - acc: 0.9565 - val_loss: 6.2985 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.96510\n",
      "Epoch 232/10000\n",
      " 3712/10000 [==========>...................] - ETA: 1:19 - loss: 5.6505 - acc: 0.9677"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-39ffa4e2ca35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#Continue training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "#model = load_model('weights-improvement-72-0.60.hdf5')\n",
    "\n",
    "filepath=\"D:\\src\\weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#Continue training\n",
    "history = model.fit(train_set,train_label,epochs=10000,batch_size=32, callbacks=callbacks_list, validation_data=(val_set,val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(base_dir, 'test')\n",
    "test_set = np.ndarray(shape=(train_num, IMAGE_HEIGHT, IMAGE_WIDTH),dtype=np.float32)\n",
    "test_label = np.ndarray(shape=(train_num, MAXLABEL),dtype=np.float32)\n",
    "test_num = 10000\n",
    "for i in range(test_num) :\n",
    "    fname = '{}.png'.format(i)\n",
    "    file = os.path.join(test_dir,fname)\n",
    "    img = image.load_img(file, target_size=(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "    arr = np.asarray(img,dtype=\"float32\")/255.0\n",
    "    arr = convert2gray(arr)\n",
    "    test_set[i] = arr    \n",
    "    test_label[i] = num2vec(i)\n",
    "\n",
    "test_set = test_set.reshape((test_num,IMAGE_HEIGHT, IMAGE_WIDTH,1))\n",
    "real_label = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 5, 4], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alabel = real_label[4535].reshape(4,10)\n",
    "alabel.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
